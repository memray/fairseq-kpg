#!/usr/bin/env bash

#/home/ubuntu/anaconda3/bin/conda config --set env_prompt '({name})'
#/home/ubuntu/anaconda3/bin/conda activate /home/ubuntu/efs/.conda/kp

export TOKENIZERS_PARALLELISM=false
export WANDB_NAME=bottleneck-bert.attention.lr=1e4
export WANDB_API_KEY=72618587b1afa7c116440deb53224bd999919d0f
export CUDA_VISIBLE_DEVICES=0,1,2,3

cd /zfs1/hdaqing/rum20/kp/fairseq-kpg/fairseq_cli

NUM_BOTTLENECK_TOKEN=4
MAX_SEQ_LEN=512
UPDATE_FREQ=16
SEED=7

source ~/.bash_profile # reload LD_LIBRARY due to error ImportError: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found

mkdir /zfs1/pbrusilovsky/rum20/google/exp/freezable/bottleneck.attention/
# w/o loading pretrained checkpoint
#PYTHONUNBUFFERED=1;LD_LIBRARY_PATH=/usr/lib64:/ihome/crc/install/cuda/10.0.130/lib64/stubs:/ihome/crc/install/cuda/10.0.130/lib64;CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES;TOKENIZERS_PARALLELISM=false nohup /ihome/hdaqing/rum20/anaconda3/envs/kp/bin/python3.7 train.py /zfs1/pbrusilovsky/rum20/google/data/roberta/data/wiki/train/:/zfs1/pbrusilovsky/rum20/google/data/roberta/data/book/train --valid-data /zfs1/pbrusilovsky/rum20/google/data/roberta/data/wiki/valid/:/zfs1/pbrusilovsky/rum20/google/data/roberta/data/book/valid --validate-interval-updates 5000 --arch bottleneck_bert_base --save-dir /zfs1/pbrusilovsky/rum20/google/exp/freezable/bottleneck.attention/ckpt/ --restore-file checkpoint_last.pt --task mlm_otf --bpe hf_pretrained_bpe --bpe-vocab /zfs1/pbrusilovsky/rum20/google/data/roberta/cache/hf_vocab/roberta-base-kp/vocab.json --bpe-merges /zfs1/pbrusilovsky/rum20/google/data/roberta/cache/hf_vocab/roberta-base-kp/merges.txt --dict-path /zfs1/pbrusilovsky/rum20/google/data/roberta/cache/hf_vocab/roberta-base-kp/dict.txt --bpe-dropout 0.1 --ddp-backend=no_c10d --criterion label_smoothed_cross_entropy --reset-optimizer --reset-dataloader --reset-meters --required-batch-size-multiple 1 --optimizer adam --adam-betas "(0.9, 0.98)" --adam-eps 1e-06 --lr 1e-4 --update-freq 8 --lr-scheduler polynomial_decay --label-smoothing 0.1 --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 --log-format simple --log-interval 100 --seed 7 --fixed-validation-seed 7 --bottleneck-tokens 4 --no-bos-eos --max-tokens 1536 --text-field text --clip-norm 0.0 --save-interval-updates 5000 --warmup-updates 5000 --total-num-update 100000 --num-workers 4 --find-unused-parameters --memory-efficient-fp16 --ddp-backend=no_c10d --fuse-bottleneck attention --wandb-project freezable > /zfs1/pbrusilovsky/rum20/google/exp/freezable/bottleneck.attention/train.nohup.out &

# resume
PYTHONUNBUFFERED=1;LD_LIBRARY_PATH=/usr/lib64:/ihome/crc/install/cuda/10.0.130/lib64/stubs:/ihome/crc/install/cuda/10.0.130/lib64;CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES;TOKENIZERS_PARALLELISM=false nohup /ihome/hdaqing/rum20/anaconda3/envs/kp/bin/python3.7 train.py /zfs1/pbrusilovsky/rum20/google/data/roberta/data/wiki/train/:/zfs1/pbrusilovsky/rum20/google/data/roberta/data/book/train --valid-data /zfs1/pbrusilovsky/rum20/google/data/roberta/data/wiki/valid/:/zfs1/pbrusilovsky/rum20/google/data/roberta/data/book/valid --validate-interval-updates 5000 --arch bottleneck_bert_base --save-dir /zfs1/pbrusilovsky/rum20/google/exp/freezable/bottleneck.attention/ckpt/ --restore-file checkpoint_last.pt --task mlm_otf --bpe hf_pretrained_bpe --bpe-vocab /zfs1/pbrusilovsky/rum20/google/data/roberta/cache/hf_vocab/roberta-base-kp/vocab.json --bpe-merges /zfs1/pbrusilovsky/rum20/google/data/roberta/cache/hf_vocab/roberta-base-kp/merges.txt --dict-path /zfs1/pbrusilovsky/rum20/google/data/roberta/cache/hf_vocab/roberta-base-kp/dict.txt --bpe-dropout 0.1 --ddp-backend=no_c10d --criterion label_smoothed_cross_entropy --reset-dataloader --required-batch-size-multiple 1 --optimizer adam --adam-betas "(0.9, 0.98)" --adam-eps 1e-06 --lr 1e-4 --update-freq 8 --lr-scheduler polynomial_decay --label-smoothing 0.1 --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 --log-format simple --log-interval 100 --seed 7 --fixed-validation-seed 7 --bottleneck-tokens 4 --no-bos-eos --max-tokens 1536 --text-field text --clip-norm 0.0 --save-interval-updates 5000 --warmup-updates 5000 --total-num-update 100000 --num-workers 4 --find-unused-parameters --memory-efficient-fp16 --ddp-backend=no_c10d --fuse-bottleneck attention --wandb-project freezable > /zfs1/pbrusilovsky/rum20/google/exp/freezable/bottleneck.attention/train.nohup.out &

# w/ loading pretrained checkpoint (not working yet)
#/home/ubuntu/efs/.conda/kp/bin/python3.7 train.py /home/ubuntu/efs/rum20/data/roberta/data/wiki/train/:/home/ubuntu/efs/rum20/data/roberta/data/book/train --valid-data /home/ubuntu/efs/rum20/data/roberta/data/wiki/valid/:/home/ubuntu/efs/rum20/data/roberta/data/book/valid --validate-interval 10 --save-dir /home/ubuntu/efs/rum20/data/roberta/ckpt/ --task mlm_otf --arch bottleneck_bert_base --restore-file /home/ubuntu/efs/rum20/data/roberta/cache/roberta.base/model.pt --bpe hf_pretrained_bpe --bpe-vocab /home/ubuntu/efs/rum20/data/roberta/cache/hf_vocab/roberta-base-kp/vocab.json --bpe-merges /home/ubuntu/efs/rum20/data/roberta/cache/hf_vocab/roberta-base-kp/merges.txt --dict-path /home/ubuntu/efs/rum20/data/roberta/cache/hf_vocab/roberta-base-kp/dict.txt --bpe-dropout 0.1 --ddp-backend=no_c10d --criterion label_smoothed_cross_entropy --reset-optimizer --reset-dataloader --reset-meters --required-batch-size-multiple 1 --optimizer adam --adam-betas "(0.9, 0.999)" --adam-eps 1e-08 --lr 5e-6 --update-freq $UPDATE_FREQ --lr-scheduler polynomial_decay --label-smoothing 0.1 --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 --log-format simple --log-interval 100 --seed $SEED --fixed-validation-seed $SEED --bottleneck-tokens $NUM_BOTTLENECK_TOKEN --max-tokens $MAX_SEQ_LEN --no-bos-eos --text-field text --clip-norm 0.1 --save-interval-updates 5000 --warmup-updates 5000 --total-num-update 100000 --num-workers 12 --find-unused-parameters --fp16 --ddp-backend=no_c10d --fuse-bottleneck attention --wandb-project bottleneck_bert
